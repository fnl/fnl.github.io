<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Projects</title>
        <link rel="stylesheet" href="../theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="../">fnl en España </a></h1>
                <nav><ul>
                    <li><a href="../pages/about.html">About</a></li>
                    <li class="active"><a href="../pages/projects.html">Projects</a></li>
                    <li><a href="../category/machine-learning.html">Machine Learning</a></li>
                    <li><a href="../category/miscellaneous.html">Miscellaneous</a></li>
                    <li><a href="../category/programming.html">Programming</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
    <h1 class="entry-title">Projects</h1>
    
    <p><strong>Text Mining</strong></p>
<p><a class="reference external" href="https://pypi.python.org/pypi/classipy">classipy</a></p>
<blockquote>
A command-line tool for developing statistical models that the can be used classify text (streams).
The library is based on SciKit-Learn and provides classifiers that make sense to use for this scenario:
Ridge Regression, various SVMs, Random Forest, Maximum Entropy/Logistic Regression, and Naïve Bayes classifiers.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/libfnl">libfnl</a></p>
<blockquote>
<p>My ever evolving Python 3 API and CLI for supporting all types of text mining tasks I do.
So far, this collection provides the following interfaces:</p>
<ul class="simple">
<li><tt class="docutils literal">fnlclassi.py</tt> is a tool to develop classifiers for [NER-tagged] text using <a class="reference external" href="http://scikit-learn.org/stable/">Scikit-Learn</a>.</li>
<li><tt class="docutils literal">fnlcorpus.py</tt> stores corpora of distinct origins in one unified JSON format.</li>
<li><tt class="docutils literal">fnldictag.py</tt> is an light-weight approach to tag tokens using a dictionary.</li>
<li><tt class="docutils literal">fnlgpcounter.py</tt> scans and counts gene/protein symbols in MEDLINE.</li>
<li><tt class="docutils literal">fnlkappa.py</tt> is a script to do inter-annotator agreement evaluations that work well with
corpora annotated using our online <a class="reference external" href="http://myminer.armi.monash.edu.au">MyMiner</a> corpora generation tool.</li>
<li><tt class="docutils literal">fnlsegtrain.py</tt> and <tt class="docutils literal">fnlsegment.py</tt> form a suite to train and use an <em>unsupervised</em>
sentence segmentation model for text via the <a class="reference external" href="http://www.nltk.org/">NLTK</a> PunktSentenceTokenizer.</li>
</ul>
</blockquote>
<p><a class="reference external" href="https://github.com/fnl/txtfnnl">txtfnnl</a></p>
<blockquote>
A modular, command-line based text mining pipeline for biomedicine using the UIMA framework.
It provides a set of Annotation Engine (AE) modules that can be combined to run more complex text
mining tasks such as Gene Normalization (assigning DB IDs to gene symbols) or mining for
biological events (e.g., transcription regulation interactions). My framework adds a special
builder pattern implementation to make UIMA/uimaFIT AEs and Resources less of a chore to develop,
maintain, and configure. In addition, my framework provides a &quot;type-free&quot; &quot;one-model-fits-all&quot;
type system, that is a single text annotation type with an <tt class="docutils literal">annotator&#64;namespace:identifier</tt>
schema to make any kind of annotations on a UIMA SOFA and thus get rid of the issues of having
specific UIMA type systems for every other AE developed by other programmers. Last, it has
specialized wrappers for the Apache Tika project (a library to extract text content from many
different file-types) that add functionality beyond the raw extraction alone, particularly for
parsing XML from important publishing houses such as Elsevier or PMC. Given how much time it
takes to build useful Java tools compared to my usual Python/C/C++ combo approach, I have
heavily reduced the time I spend on this project, but it provides a number of useful tools,
particularly it is fully capable of doing the NLP pre-processing of arbitrary input files
(Word, PDFs, XML, etc.), including (supervised) sentence segmenting, tokenization, PoS-tagging,
and phrase chunking.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/segtok">segtok</a></p>
<blockquote>
A (surprisingly popular - hence not under sidekicks) library and command-line tool to split sentences and tokenize words (incl. genes/chemicals, date/time, email/web addresses, etc.) using regular expressions.</blockquote>
<p><strong>Bioinformatics</strong></p>
<p><a class="reference external" href="https://pypi.python.org/pypi/medic/">medic</a></p>
<blockquote>
A command-line tool to manage an up-to-date PubMed/MEDLINE DB mirror. This is a Python 3 program
that allows you to bootstrap a MEDLINE Citation (PubMed Abstracts) repository in either SQLite or
PostgreSQL (Technically, it uses SQL Alchemy, so a few other datastores seem to be OK, too.) You
can import data directly from the NCBI eUtils web service or by parsing MEDLINE XML files.
Content can be extracted in plain-text (full, TIAB only, or as a table) or HTML format.
The easiest way to install it is from PyPi, using &quot;<tt class="docutils literal">pip3 install medic</tt>&quot;.
To use it, check out &quot;<tt class="docutils literal">medic <span class="pre">--help</span></tt>&quot; and &quot;<tt class="docutils literal">man medic</tt>&quot;.
So far, this is my project that as been most often used by fellow researchers and
therefore I dare claim it is <em>production ready</em>. With their great help, many bugs on different
platforms and using various datastores have been discovered and elminiated (And, if you find any
more, I do try to have a fix ready for you in less than 24 hours.)</blockquote>
<p><a class="reference external" href="https://github.com/fnl/gnamed">gnamed</a></p>
<blockquote>
A command-line tool to maintain an up-to-date repository of gene and protein names together with
their most important keywords (kDa, length, chromosome position, etc.) and their references to
the NCBI taxonomy and to PubMed. This is particularly useful to build gene normalization systems.
Beyond just dumping the data, this tool groups unique genes and proteins from different databases
and links all those proteins and genes (as a <tt class="docutils literal">n to m</tt> relation).
To use it, clone it from GitHub (&quot;<tt class="docutils literal">git clone git&#64;github.com:fnl/gnamed.git</tt>&quot;) and install it
locally (&quot;<tt class="docutils literal"><span class="pre">virtualenv-3.3</span> gnamed; cd gnamed; . bin/activate; python3 setup.py install</tt>&quot;).
Then, you can learn about it by using <tt class="docutils literal">man gnamed</tt> (or, just follow the link to the tool...)</blockquote>
<p><a class="reference external" href="http://www.biocreative.org">BioCreative</a></p>
<blockquote>
An international project, organizing community challenges in text mining for molecular biology.
I in particular have been the main organizer of one of these challenges, BioCreative II.5, and
have been the developer of the Django-based website the organization uses to manage these events
and their participants. Another integral part of this project is my official <a class="reference external" href="https://github.com/fnl/bceval">bceval</a> evaluation
tool to measure the performance of the participating text mining systems.</blockquote>
<p><a class="reference external" href="http://myminer.armi.monash.edu.au">MyMiner</a></p>
<blockquote>
An online corpus annotation tool I collaborated with (But the development was done by <a class="reference external" href="http://umr910.timone.univ-mrs.fr/member.php?lang=en&amp;name=1&amp;or=te">David Salgado</a>.)</blockquote>
<p><a class="reference external" href="https://github.com/fnl/tred">tred</a></p>
<blockquote>
Load (parts of) the <a class="reference external" href="http://rulai.cshl.edu/cgi-bin/TRED/tred.cgi?process=home">Transcriptional Regulatory Element Database</a> into a PostgreSQL DB.</blockquote>
<p><strong>Sidekicks and Minor Projects</strong></p>
<p><a class="reference external" href="https://github.com/fnl/lexicos">lexicos</a></p>
<blockquote>
A data-structure implementing a minimal acyclic deterministic finite state automaton in Scala.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/libfsmg">libfsmg</a></p>
<blockquote>
A generic finite state machine library in Java.
Design your own grammar to quickly build generic pattern matching engines.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/patricia-trie">patricia-trie</a></p>
<blockquote>
A PATRICIA tree implementation in pure Python; to install, run <tt class="docutils literal">pip install <span class="pre">patricia-trie</span></tt>.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/couchdb_client">couchdb_client</a></p>
<blockquote>
A tiny and very efficient JavaScript/Node.js client for CouchDB.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/word2numpy">word2numpy</a></p>
<blockquote>
My port of the <a class="reference external" href="http://radimrehurek.com/gensim/">Gensim</a> <tt class="docutils literal">word2vec.py</tt> Python 2 script to 3. <a class="reference external" href="https://code.google.com/p/word2vec/">word2vec</a> in turn is a
(Google) ANN to detect semantic relationships between words using word vectors.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/progress_bar">progress_bar</a></p>
<blockquote>
A simply Python 2/3 tool (install via <tt class="docutils literal">pip install progress_bar</tt>) to display progress bars
in a terminal with a bar header and adapted to the width of the terminal.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/ungreek">ungreek</a></p>
<blockquote>
Tools to expand Greek letters to Latin names and to replace non-ASCII characters with their
closest ASCII-representation.</blockquote>
<p><a class="reference external" href="https://github.com/fnl/tokenizer">tokenizer</a></p>
<blockquote>
A parallel, high-throughput tokenizer using a deterministic finite state automaton written in
Go (&quot;golang&quot;).</blockquote>

</section>
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>